{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\") # include parent dir\n",
    "\n",
    "from jlonevae_lib.architecture.load_model import load_model\n",
    "import jlonevae_lib.architecture.vae_jacobian as vj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see dataset formatting instructions\n",
    "# at https://github.com/rr-learning/disentanglement_dataset\n",
    "rawdata = np.load(\"../../data/mpi3d_real/mpi3d_real.npz\")['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inds has four rows, each row has a list of data indices for images to use\n",
    "# shape is 4 by num, and the values are all between 0 and 1036800-1\n",
    "def get_multi_data(allinds):\n",
    "    inner_imgs = []\n",
    "    for quartinds in allinds:\n",
    "        inner_imgs.append(rawdata[quartinds][:,0:64:2,0:64:2,:] / 255.)\n",
    "    # combine all 4 sampled images into one image\n",
    "    # index 0 of inner_imgs is image sample number\n",
    "    #print(inner_imgs[0].shape)\n",
    "    return np.concatenate((\n",
    "                 np.concatenate((inner_imgs[0],inner_imgs[1]),axis=1),\n",
    "                 np.concatenate((inner_imgs[2],inner_imgs[3]),axis=1)), axis=2).transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    factor_sizes = [6, 6, 2, 3, 3, 40, 40]\n",
    "    factor_bases = np.prod(factor_sizes) / np.cumprod(\n",
    "            factor_sizes)\n",
    "    all_factors = np.random.randint(40,size=(4,7))\n",
    "    all_factors[:,0] = 3\n",
    "    all_factors[:,1] = 1\n",
    "    all_factors[:,2] = 1 \n",
    "    all_factors[:,3] = 0 \n",
    "    all_factors[:,4] = 2 \n",
    "    allinds = np.array(np.dot(all_factors, factor_bases), dtype=np.int64).reshape([4,1])\n",
    "    imgs = get_multi_data(allinds)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(get_data()[0].transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedOutputs = \"trainedModels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "def get_model_and_enc(gammastring, data, timestamp=\"*\"):\n",
    "    base_locs = np.array([[32/64., 16/64.],[48/64,32/64.],[16/64.,48/64.]])\n",
    "    matching_model_paths = glob.glob(f\"../{combinedOutputs}/defaultConv_lone_beta0_0100_ica{gammastring}_lat10_batch64_lr0_0001_anneal100000/{timestamp}/representation/cache_batch_no300000\")\n",
    "    model_path = matching_model_paths[0]\n",
    "\n",
    "    model = load_model(model_path,device).double();\n",
    "    encoding, logvar = model.encode(torch.tensor(data).double().to(device));\n",
    "    return model, encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T15:39:00.367894Z",
     "start_time": "2021-04-21T15:39:00.356332Z"
    }
   },
   "source": [
    "# Find the most active columns and plot them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = \"./mpi3dMultiJacobians/\"\n",
    "from pathlib import Path\n",
    "Path.mkdir(Path(outputdir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = get_data()\n",
    "for gammastring in (\"0_0100\", \"0_0000\"):\n",
    "    model, encoding = get_model_and_enc(gammastring,data)\n",
    "    rec = model.decode(torch.tensor(encoding).double().to(device))\n",
    "    rec = rec.detach().cpu().numpy()[0].transpose(1,2,0)\n",
    "    plt.imshow(data[0].transpose(1,2,0));plt.show();plt.close();\n",
    "    # convert RGB to BGR and scale to 0-255\n",
    "    cv2.imwrite(outputdir+\"Mpi3dMulti-ExampleImage.png\", (data[0].transpose(1,2,0)*255)[:,:,(2,1,0)]);\n",
    "    plt.imshow(rec);plt.show();plt.close();\n",
    "    cv2.imwrite(outputdir+f\"Mpi3dMulti-ReconImageGamma{gammastring}.png\", (rec*255)[:,:,(2,1,0)]);\n",
    "    # contrast adjustment for jacobian\n",
    "    scale = 5\n",
    "    jacs = vj.compute_generator_jacobian_analytic(model, encoding, device=device,\n",
    "                                        im_channels=3)#.detach().cpu().numpy()\n",
    "    activities = [np.sum(np.square(jac)) for jac in jacs]\n",
    "    top_jac_inds = np.flip(np.argsort(activities))\n",
    "    gsc = np.std(np.abs(jacs))\n",
    "    for q, ind in enumerate(top_jac_inds):\n",
    "        print(jacs[ind].squeeze().shape)\n",
    "        added_constrast_jac = jacs[ind,0].transpose(1,2,0) /gsc * 0.1\n",
    "        added_constrast_jac = np.abs(added_constrast_jac)\n",
    "        plt.imshow(added_constrast_jac);plt.show();plt.close();\n",
    "        print(np.min(added_constrast_jac), np.max(added_constrast_jac))\n",
    "        cv2.imwrite(outputdir+\"Mpi3dMulti-JacGamma%sLatent%d.png\" %(gammastring,q), 255*added_constrast_jac[:,:,(2,1,0)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
