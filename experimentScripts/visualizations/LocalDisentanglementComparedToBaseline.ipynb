{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "gray = (167/255, 168/255, 170/255, 1)\n",
    "red = (179/255, 27/255, 27/255, 1)\n",
    "blue = (0,47/255, 108/255,1)\n",
    "markersize=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use this logic for filtering multiple runs\n",
    "resultsMustBeAfter = time.struct_time((2021, 5, 25, 0, 0, 0, 0, 0, 0))\n",
    "tResultsMustBeAfter = time.mktime(resultsMustBeAfter)\n",
    "print(tResultsMustBeAfter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWithColor(evaluation_filepaths, xval=0, color=\"black\", desired_locality=0.1):\n",
    "    data=[]\n",
    "    for ind, filename in enumerate(evaluation_filepaths):\n",
    "        tFile = os.path.getmtime(filename)\n",
    "        if (tFile < tResultsMustBeAfter):\n",
    "            continue\n",
    "        evaluation_results = json.loads(\n",
    "                open(filename, \"r\").read())\n",
    "        locality = float(evaluation_results[\"evaluation_config.local_sample_factors.locality_proportion\"])\n",
    "        # I concerned.\n",
    "        if locality != desired_locality:\n",
    "            continue\n",
    "        met_samps = evaluation_results[metvalname]\n",
    "        data.append(np.mean(met_samps))\n",
    "    vplot = plt.violinplot(np.array(data), [xval], points=20, widths=0.3, showextrema=True, showmedians=True)\n",
    "    for partname in ('cbars','cmins','cmaxes','cmedians'):\n",
    "        vp = vplot[partname]\n",
    "        vp.set_edgecolor(color)\n",
    "        vp.set_linewidth(5)\n",
    "        vp.set_alpha(1)\n",
    "    for name in [\"bodies\"]:\n",
    "        for pc in vplot[name]:\n",
    "            pc.set_facecolor(color)\n",
    "            pc.set_edgecolor(color)\n",
    "            pc.set_alpha(0.5)\n",
    "    return data # so we can run t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = \"'threeDots'\" # note single quotes to match evaluation_results\n",
    "# combinedOutputs is the path from the root directory to the JL1-VAE models. \n",
    "# If unzipping pre-trained models you may need to change this path. \n",
    "# This path works for models trained and evaluated with\n",
    "# ./experimentScripts/train_jlonevae/train_threeDots.bash\n",
    "# ./experimentScripts/evaluate_jlonevae/evaluate_threeDots.bash\n",
    "# which stores models and evaluations in directories like:\n",
    "# ./trainedModels/defaultConv_lone_beta4_0000_ica0_1000_lat10_batch64_lr0_0001_anneal100000/20210604-014949/representation\n",
    "combinedOutputs = \"trainedModels\"\n",
    "# If unzipping pre-trained models you may need to change this path.\n",
    "# For example, if you download \"combinedOutputsThreeDotsReplicationRunFinal.zip\"\n",
    "# and unzip it into the directory \"threeDotsDownload\",\n",
    "# then you should use filepath:\n",
    "combinedOutputs = \"threeDotsDownload/combinedOutputs/threeDots\"\n",
    "\n",
    "\n",
    "# trainedStandardModels is the path from the root directory to the standard baseline models.\n",
    "# If unzipping pre-trained models you may need to change this path. \n",
    "# This path works for models trained and evaluated with\n",
    "# ./experimentScripts/train_baseline/train_standard_tf_models.bash\n",
    "# ./experimentScripts/evaluate_baseline/postprocess_baseline_threeDots.bash\n",
    "# ./experimentScripts/evaluate_baseline/evaluate_baseline.bash\n",
    "# which stores models in directories like:\n",
    "# ./trainedStandardModels/model101_on3dots/20210602-142643/\n",
    "trainedStandardModels = \"trainedStandardModels\"\n",
    "# Likewise, if you're unzipping pre-trained models you may need to update that path,\n",
    "# depending on where you unzip the pretrained models to.\n",
    "# For example, if you unzip each of the modelXXX_on3dots.zip files into their own folder\n",
    "# inside, eg., ./standardModelsDownload/modelXXX_on3dots.zip then you can use\n",
    "#trainedStandardModels = \"standardModelsDownload\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataDicts = []\n",
    "for metric, metvalname in [(\"local_mig_0_1\",\"evaluation_results.local_discrete_migs_samples\"), \n",
    "               (\"local_modularity_0_1\",\"evaluation_results.local_modularity_scores_samples\")]:\n",
    "    f = plt.figure(figsize=(10,8))\n",
    "    ticklabels = [\"JL1-VAE\\n(ours)\"]\n",
    "    for minx, modgrp in enumerate([10,40,70,100,130,160]):\n",
    "        evaluation_filepaths = glob.glob(f\"../../{trainedStandardModels}/model{modgrp}?_on3dots/*/metrics/{metric}*/results/aggregate/evaluation.json\")\n",
    "        print(evaluation_filepaths)\n",
    "        disentangVals = plotWithColor(evaluation_filepaths, xval=minx+1, color=blue)\n",
    "        evaluation_results = json.loads(\n",
    "                open(evaluation_filepaths[0], \"r\").read())\n",
    "        methodname = evaluation_results['train_config.model.name']\n",
    "        if evaluation_results['evaluation_config.dataset.name'] != datasetName:\n",
    "                    print(f\"Skipping model evaluated on {evaluation_results['evaluation_config.dataset.name']}\")\n",
    "                    continue\n",
    "        ticklabels.append(methodname.replace(\"'\",\"\").replace(\"_\",\"-\").replace(\"vae\",\"VAE\"))\n",
    "        dataDicts.append((methodname, disentangVals))\n",
    "    \n",
    "    evaluation_filepaths = glob.glob(f\"../../{combinedOutputs}/*ica0_1000_lat10*/*/metrics/{metric}*/results/aggregate/evaluation.json\")\n",
    "    print(evaluation_filepaths)\n",
    "    ourDisentangVals = plotWithColor(evaluation_filepaths, color=red)\n",
    "    \n",
    "    plt.ylabel(metric.replace(\"_\",\" \").replace(\"mig\",\"MIG\"))\n",
    "    plt.xticks(range(len(ticklabels)), ticklabels, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    f.savefig(f\"threeDots_{metric}_compareToStandard.png\")\n",
    "    plt.show();plt.close()\n",
    "    \n",
    "    import scipy.stats\n",
    "    for methodname, disentangVals in dataDicts:\n",
    "        print(methodname)\n",
    "        print(scipy.stats.ttest_ind(ourDisentangVals, disentangVals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
